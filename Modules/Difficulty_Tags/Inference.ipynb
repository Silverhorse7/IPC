{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh1as7BU5CeX",
        "outputId": "621ea612-526f-422a-85a6-62e790f0a61a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVXwLjH5YSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, RobertaTokenizer\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, auc\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87gHRDJz5ZrT"
      },
      "outputs": [],
      "source": [
        "state = torch.load('/content/model.pt', map_location=torch.device('cpu')) # \"Please input the path to the saved model.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHtFkPck5ayP"
      },
      "outputs": [],
      "source": [
        "model_state_dict = {}\n",
        "tag_state_dict = {}\n",
        "rating_state_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kv9Lb_n5cE6"
      },
      "outputs": [],
      "source": [
        "for k, v in state.items():\n",
        "    if \"model.\" in k:\n",
        "        name = k[6:]\n",
        "        model_state_dict[name] = v\n",
        "    if \"tags_classifier.\" in k:\n",
        "        name = k[len(\"tags_classifier.\"):]\n",
        "        tag_state_dict[name] = v\n",
        "    if \"ratings_classifier.\" in k:\n",
        "        name = k[len(\"ratings_classifier.\"):]\n",
        "        rating_state_dict[name] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajRRg8VN5djP"
      },
      "outputs": [],
      "source": [
        "AMT10 = [\n",
        "    'implementation',\n",
        "    'dp',\n",
        "    'math',\n",
        "    'greedy',\n",
        "    'data structures',\n",
        "    'brute force',\n",
        "    'geometry',\n",
        "    'constructive algorithms',\n",
        "    'dfs and similar',\n",
        "    'strings'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inB6eg_L5eqI"
      },
      "outputs": [],
      "source": [
        "model_config = AutoConfig.from_pretrained(\"google/bigbird-roberta-base\", max_position_embeddings=1024)\n",
        "model_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UJChA065gG7"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'seed' : 42,\n",
        "    'tags' : AMT10,\n",
        "    'batchSize' : 4,\n",
        "    'lr' : 5e-6,\n",
        "    'trainMaxLength' : 1024,\n",
        "    'testMaxLength' : 1024,\n",
        "    'numEpochs' : 200,\n",
        "    'model' : AutoModel.from_config(model_config),\n",
        "    'tokenizer' : RobertaTokenizer.from_pretrained('roberta-base'),\n",
        "    'gradient_accumulation_steps' : 4,\n",
        "    'max_grad_norm' : 1.0,\n",
        "    'lambda' : 10,\n",
        "    'save' : True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgA3QJKB5h2z"
      },
      "outputs": [],
      "source": [
        "# Define a class for multi-label classification head\n",
        "class MultiLabelClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(hidden_size, num_labels)  # Fully connected layer\n",
        "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)  # Apply the fully connected layer\n",
        "        x = self.sigmoid(x)  # Apply the sigmoid activation\n",
        "        return x\n",
        "\n",
        "# Define a class for multi-class classification head\n",
        "class MultiClassClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(hidden_size, num_labels)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)  # Apply the fully connected layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdZeMTop5kTP"
      },
      "outputs": [],
      "source": [
        "model = config['model']\n",
        "tag_head = MultiLabelClassificationHead(10)\n",
        "rating_head = MultiClassClassificationHead(28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6yxacyf5loC"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(model_state_dict)\n",
        "tag_head.load_state_dict(tag_state_dict)\n",
        "rating_head.load_state_dict(rating_state_dict)\n",
        "print('fin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLyW6aH_5nFW"
      },
      "outputs": [],
      "source": [
        "# Set the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the chosen device\n",
        "model.to(device)\n",
        "tag_head.to(device)\n",
        "rating_head.to(device)\n",
        "print('device : ', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0haCmX4h5och"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/AMT10_train.csv', index_col=0, encoding='utf8')\n",
        "test_df = pd.read_csv('/content/AMT10_test.csv', index_col=0, encoding='utf8')\n",
        "pred_df = pd.read_csv('/content/combined_problems.csv', index_col=0, encoding='utf8')\n",
        "\n",
        "# test_df = test_df[:100]\n",
        "# pred_df = pred_df[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ZpZfzD5pva"
      },
      "outputs": [],
      "source": [
        "new_train_idx = []  # List to store new indices\n",
        "selected_train_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in train_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(train_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_train_tags.append(t)\n",
        "        new_train_idx.append(index)\n",
        "\n",
        "print(len(new_train_idx))  # Print the length of the new index list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXTiXoh-5rLe"
      },
      "outputs": [],
      "source": [
        "new_valid_idx = []  # List to store new indices\n",
        "selected_valid_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in test_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(test_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_valid_tags.append(t)\n",
        "        new_valid_idx.append(index)\n",
        "\n",
        "print(len(new_valid_idx))  # Print the length of the new index list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkyaSn9C5sZh"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.loc[new_train_idx]\n",
        "train_df['tags'] = selected_train_tags\n",
        "\n",
        "y_tags_train = train_df['tags']\n",
        "y_ratings_train = train_df['rating'].astype(int)\n",
        "\n",
        "X_pred = pred_df['problem_statement']\n",
        "\n",
        "test_df = test_df.loc[new_valid_idx]\n",
        "test_df['tags'] = selected_valid_tags\n",
        "X_test = test_df['description']\n",
        "y_tags_test = test_df['tags']\n",
        "y_ratings_test = test_df['rating'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr1zx5iD5tsi"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the MultiLabelBinarizer\n",
        "tag_label_encoder = MultiLabelBinarizer()\n",
        "rating_label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder on the labels and transform them\n",
        "y_tags_train = tag_label_encoder.fit_transform(y_tags_train)\n",
        "y_tags_test = tag_label_encoder.transform(y_tags_test)\n",
        "\n",
        "y_ratings_train = rating_label_encoder.fit_transform(y_ratings_train)\n",
        "y_ratings_test = rating_label_encoder.transform(y_ratings_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo1x8jIz5u8e"
      },
      "outputs": [],
      "source": [
        "def tokenizing(tokenizer, data, max_length):\n",
        "    # Tokenize and encode the text input\n",
        "    data = list(data.values)\n",
        "    tokenized_data = tokenizer(data, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "\n",
        "    return tokenized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qo0b2565wCT"
      },
      "outputs": [],
      "source": [
        "tokenizer = config['tokenizer']\n",
        "tokenized_inputs_test = tokenizing(tokenizer, X_test, config['testMaxLength'])\n",
        "tokenized_inputs_pred = tokenizing(tokenizer, X_pred, config['testMaxLength'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUlVXdWh5xv2"
      },
      "outputs": [],
      "source": [
        "def convert_to_tensor(data, dtype):\n",
        "    # Convert data to tensors\n",
        "    tensor_data = torch.tensor(data, dtype=dtype)\n",
        "    return tensor_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D2cCcmJ5zpc"
      },
      "outputs": [],
      "source": [
        "tags_labels_test = convert_to_tensor(y_tags_test, dtype=torch.float)\n",
        "ratings_labels_test = convert_to_tensor(y_ratings_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBzYPueZ5038"
      },
      "outputs": [],
      "source": [
        "test_dataset = TensorDataset(tokenized_inputs_test['input_ids'], tokenized_inputs_test['attention_mask'], tags_labels_test, ratings_labels_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=config['batchSize'], shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "pred_dataset = TensorDataset(tokenized_inputs_pred['input_ids'], tokenized_inputs_pred['attention_mask'])\n",
        "pred_dataloader = DataLoader(pred_dataset, batch_size=config['batchSize'], shuffle=False, num_workers=8, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABYt58YG53Wa"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "tag_head.eval()\n",
        "rating_head.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    thresholds = [0.001] + [i * 0.01 for i in range(1, 101)]\n",
        "    tags_true = []\n",
        "    tags_pred = defaultdict(list)\n",
        "    tags_pred_proba = []\n",
        "\n",
        "    ratings_true = []\n",
        "    ratings_pred = []\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        ## Unpack the batch\n",
        "        input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "        # Move the inputs and labels to the chosen device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        tags_labels = tags_labels.to(device)\n",
        "        ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        tags_output = tag_head(pooled_output)\n",
        "        ratings_output = rating_head(pooled_output)\n",
        "\n",
        "        # tags\n",
        "        tags_true.extend([torch.nonzero(row).flatten().tolist() for row in tags_labels.detach().cpu().clone()])\n",
        "        tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "        ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "        ratings_true.extend(ratings_labels.detach().cpu().clone())\n",
        "\n",
        "        # Extract indices with values greater than or equal to the threshold.\n",
        "        for threshold in thresholds:\n",
        "            tags_pred[threshold].extend([(row >= threshold).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "    rating_true = [tensor.detach().cpu().clone().item() for tensor in ratings_true]\n",
        "    rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "    revise_rating_pred = []\n",
        "\n",
        "    for i in range(len(rating_pred)):\n",
        "        if abs(rating_true[i] - rating_pred[i]) <= 1:\n",
        "            revise_rating_pred.append(rating_true[i])\n",
        "        else:\n",
        "            revise_rating_pred.append(rating_pred[i])\n",
        "\n",
        "    rating_pred = revise_rating_pred\n",
        "\n",
        "    tag_true = []\n",
        "\n",
        "    for index_list in tags_true:\n",
        "        result_true = [0] * 10  # Create a list of length num_classes.\n",
        "        for index in index_list:\n",
        "            result_true[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "        tag_true.append(result_true)\n",
        "\n",
        "    tag_true = np.array(tag_true)\n",
        "    tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "    thr = 0\n",
        "    max_f1_score = 0\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        tag_pred = []\n",
        "        for index_list in tags_pred[threshold]:\n",
        "            result_pred = [0] * 10 # Create a list of length num_classes.\n",
        "            for index in index_list:\n",
        "                result_pred[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "            tag_pred.append(result_pred)\n",
        "\n",
        "        f1 = f1_score(tag_true, tag_pred, average='macro', zero_division=0)\n",
        "        if max_f1_score < f1:\n",
        "            thr = threshold\n",
        "            max_f1_score = f1\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "\n",
        "    # Plot ROC curve for each classifier\n",
        "    plt.figure()\n",
        "    for num_classes in range(10):\n",
        "        tt, tp = tag_true[:, num_classes], tags_pred_proba[:, num_classes]\n",
        "\n",
        "        score = roc_auc_score(tt, tp)\n",
        "        tag = tag_label_encoder.classes_[num_classes]\n",
        "        print(f\"{tag} : {score}\")\n",
        "        fpr[num_classes], tpr[num_classes], _ = roc_curve(tt, tp)\n",
        "        plt.plot(fpr[num_classes], tpr[num_classes], label=f'{tag}(area={score:.2f})')\n",
        "    print()\n",
        "\n",
        "    print(\"tag_roc_auc_score : \", roc_auc_score(tag_true, tags_pred_proba))\n",
        "    print(\"f1_score : \", max_f1_score)\n",
        "    print(\"threshold : \", thr)\n",
        "\n",
        "    rating_acc = accuracy_score(rating_true, rating_pred)\n",
        "    print(f\"rating_acc : {rating_acc}\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Tag Prediction')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    tags_pred = []\n",
        "    tags_pred_proba = []\n",
        "\n",
        "    ratings_pred = []\n",
        "    for batch in tqdm(pred_dataloader):\n",
        "        ## Unpack the batch\n",
        "        input_ids, attention_mask = batch\n",
        "\n",
        "        # Move the inputs and labels to the chosen device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        tags_output = tag_head(pooled_output)\n",
        "        ratings_output = rating_head(pooled_output)\n",
        "\n",
        "        # tags\n",
        "        tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "        ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "\n",
        "        # Extract indices with values greater than or equal to the threshold.\n",
        "        tags_pred.extend([(row >= thr).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "    rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "    rating_pred = [rating_label_encoder.classes_[i] for i in rating_pred]\n",
        "\n",
        "    tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "    tag_pred = []\n",
        "    for index_list in tags_pred:\n",
        "        result_pred = []\n",
        "        for index in index_list:\n",
        "            result_pred.append(tag_label_encoder.classes_[index])\n",
        "\n",
        "        tag_pred.append(result_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
